{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Approval Prediction\n",
    "Edmund Walsh - May 10th, 2020\n",
    "\n",
    "## Introduction\n",
    "The project examines the data provided by the Home Mortgage Disclosure Act (HMDA) which requires mortgage lenders in the United States to disclose information about the mortgage lending decisions they have made. Specifically, we will be examining prediction of whether or not an application will be accepted or denied.\n",
    "\n",
    "This notebook is part of a short 5-day project whose purpose goes beyond the acceptance prediction of mortgages. The focus of this project is more about the process and end-to-end engineering from raw data to results and presentation. This notebook will focus on the data science approach and process and highlight a roadmap best illustrated in the image below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://miro.medium.com/max/1400/1*LoBdYL_YyIcYJ842peLDpQ.jpeg'\n",
    "     alt='Data Science & Data Engineering'\n",
    "     style='height: 350px; width: 750px;' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Ground Up Approach\n",
    "The pyramid above is such a good illustration because the process truly is building in a step-by-step fashion \n",
    "towards the ultimate goal of finding useful results that are actionable and impactful in the real world. \n",
    "The end results get all of the attention, but a project is unlikely to be successful without these strong foundations.\n",
    "\n",
    "## Context \n",
    "While this project request didn't specifically state 'why' we are looking into this data, I will work within the context of three important rationales.\n",
    "1. Mortgage due diligence is expensive and time intensive. A process that can more reliably expidite the process will save lenders significant time and resources.\n",
    "2. From a regulatory perspective and also importantly as Machine Intelligence becomse a larger and more common part of this process it is important for us to be aware of and highlight any bias.\n",
    "3. Some financial instituions may be more or less likely to issue mortgages and this may reflect either an over or under utilization of the balance sheet or their risk appetite.\n",
    "\n",
    "### Preparation\n",
    "Before digging in, let's install our python requirements and follow the instructions for setting up our docker environment and tools in the [README.md](file:///../README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2_binary==2.7.5 in c:\\python37\\lib\\site-packages (from -r ./misc/requirements.txt (line 1)) (2.7.5)\n",
      "Requirement already satisfied: pandas==0.24.1 in c:\\python37\\lib\\site-packages (from -r ./misc/requirements.txt (line 2)) (0.24.1)\n",
      "Requirement already satisfied: psycopg2==2.8.2 in c:\\users\\dell\\appdata\\roaming\\python\\python37\\site-packages (from -r ./misc/requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: PyYAML==5.1 in c:\\users\\dell\\appdata\\roaming\\python\\python37\\site-packages (from -r ./misc/requirements.txt (line 4)) (5.1)\n",
      "Requirement already satisfied: numpy==1.17.2 in c:\\python37\\lib\\site-packages (from -r ./misc/requirements.txt (line 5)) (1.17.2)\n",
      "Requirement already satisfied: pendulum==2.0.5 in c:\\python37\\lib\\site-packages (from -r ./misc/requirements.txt (line 6)) (2.0.5)\n",
      "Requirement already satisfied: pathlib2==2.3.5 in c:\\python37\\lib\\site-packages (from -r ./misc/requirements.txt (line 7)) (2.3.5)\n",
      "Requirement already satisfied: wheel==0.34.2 in c:\\python37\\lib\\site-packages (from -r ./misc/requirements.txt (line 8)) (0.34.2)\n",
      "Requirement already satisfied: matplotlib==3.2.1 in c:\\users\\dell\\appdata\\roaming\\python\\python37\\site-packages (from -r ./misc/requirements.txt (line 9)) (3.2.1)\n",
      "Requirement already satisfied: seaborn==0.10.1 in c:\\users\\dell\\appdata\\roaming\\python\\python37\\site-packages (from -r ./misc/requirements.txt (line 10)) (0.10.1)\n",
      "Requirement already satisfied: sklearn==0.0 in c:\\users\\dell\\appdata\\roaming\\python\\python37\\site-packages (from -r ./misc/requirements.txt (line 11)) (0.0)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\python37\\lib\\site-packages (from pandas==0.24.1->-r ./misc/requirements.txt (line 2)) (2019.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\python37\\lib\\site-packages (from pandas==0.24.1->-r ./misc/requirements.txt (line 2)) (2.8.0)\n",
      "Requirement already satisfied: pytzdata>=2018.3 in c:\\python37\\lib\\site-packages (from pendulum==2.0.5->-r ./misc/requirements.txt (line 6)) (2019.3)\n",
      "Requirement already satisfied: six in c:\\python37\\lib\\site-packages (from pathlib2==2.3.5->-r ./misc/requirements.txt (line 7)) (1.12.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python37\\lib\\site-packages (from matplotlib==3.2.1->-r ./misc/requirements.txt (line 9)) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python37\\lib\\site-packages (from matplotlib==3.2.1->-r ./misc/requirements.txt (line 9)) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\python37\\lib\\site-packages (from matplotlib==3.2.1->-r ./misc/requirements.txt (line 9)) (2.4.5)\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\python37\\lib\\site-packages (from seaborn==0.10.1->-r ./misc/requirements.txt (line 10)) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\appdata\\roaming\\python\\python37\\site-packages (from sklearn==0.0->-r ./misc/requirements.txt (line 11)) (0.22.2.post1)\n",
      "Requirement already satisfied: setuptools in c:\\python37\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib==3.2.1->-r ./misc/requirements.txt (line 9)) (40.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\dell\\appdata\\roaming\\python\\python37\\site-packages (from scikit-learn->sklearn==0.0->-r ./misc/requirements.txt (line 11)) (0.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user -r ./misc/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Import\n",
    "Now we can begin importing the required packages. Many of these are common python packages, the exception is seed which is a set of functions we will use to import our initial data and begin our collect step on our roadmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import config\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Discussion of the data\n",
    "Our data sources will come from three major sources and we will use their APIs to download the data.\n",
    "1. Our main dataset comes from the HMDA database and includes not only a large set of information about the individual loan approval decision but also information about the originating institutions.\n",
    "    a. A full list of available data on the mortgage approvals can be found [here](http://cfpb.github.io/api/hmda/fields.html)\n",
    "    b. We also will look at the originating instituions and information about that dataset can be found [here](https://api.consumerfinance.gov/data/hmda/slice/institutions/metadata)\n",
    "2. Our next and complementary set of information comes from the census bureau. We will use their county business patterns series which aggregate economic information at a county level. I hope that this information will provide some valueable economic insight into regional economics that may affect an mortgage approval decision.\n",
    "    a. Details about this dataset can be found [here](https://www.census.gov/programs-surveys/cbp.html)\n",
    "    b. This API requires a key which you can sign up for [here](https://api.census.gov/data/key_signup.html)\n",
    "    c. After you have signed up, please include this key in the [config.py](file:///./config.py) file.\n",
    "3. Finally, we will also fill in some data from Federal Reserve Bank of St. Louis. This data will come into use towards the end of the project as we begin to look across time periods as it should give us an indication of both the financial conditions and sentiment of the originating institutions.\n",
    "    a. Details about this API can be found [here](https://fred.stlouisfed.org/docs/api/fred/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8dadaedad2b940dd8ffff397507286b479540d00\n"
     ]
    }
   ],
   "source": [
    "# after configuring the census API re-import config and check api key\n",
    "import config\n",
    "print(config.api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "Luckily for us, the designers of the APIs have made this pretty easy. A big thank you to them!\n",
    "\n",
    "To start, I have selected a single year and a single state. Feel free to change to your preferences, data is available from 2007 - 2017. Some important caveats. As this is an illustrative project only, there are some important details about availability of data (i.e. when it was published) and data type issues that would require more attention in a production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a first state by two letter code and year\n",
    "init_state = \"OH\"\n",
    "init_yr = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull data from the HMDA database on mortgage approvals -- this may take awhile\n",
    "data_lar = seed.lar_pull(init_state, init_yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action_taken</th>\n",
       "      <th>action_taken_name</th>\n",
       "      <th>agency_code</th>\n",
       "      <th>agency_abbr</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>applicant_ethnicity</th>\n",
       "      <th>applicant_ethnicity_name</th>\n",
       "      <th>applicant_income_000s</th>\n",
       "      <th>applicant_race_1</th>\n",
       "      <th>applicant_race_2</th>\n",
       "      <th>...</th>\n",
       "      <th>state_name</th>\n",
       "      <th>hud_median_family_income</th>\n",
       "      <th>loan_amount_000s</th>\n",
       "      <th>number_of_1_to_4_family_units</th>\n",
       "      <th>number_of_owner_occupied_units</th>\n",
       "      <th>minority_population</th>\n",
       "      <th>population</th>\n",
       "      <th>rate_spread</th>\n",
       "      <th>tract_to_msamd_income</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Loan originated</td>\n",
       "      <td>7</td>\n",
       "      <td>HUD</td>\n",
       "      <td>Department of Housing and Urban Development</td>\n",
       "      <td>2</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>66600</td>\n",
       "      <td>219</td>\n",
       "      <td>3165</td>\n",
       "      <td>2746</td>\n",
       "      <td>9.869999885559082</td>\n",
       "      <td>10439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148.33999633789062</td>\n",
       "      <td>b73debb0-35a0-4a26-b982-aed4973e497c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Application denied by financial institution</td>\n",
       "      <td>7</td>\n",
       "      <td>HUD</td>\n",
       "      <td>Department of Housing and Urban Development</td>\n",
       "      <td>2</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>69100</td>\n",
       "      <td>293</td>\n",
       "      <td>3131</td>\n",
       "      <td>2921</td>\n",
       "      <td>16.459999084472656</td>\n",
       "      <td>8742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172.69000244140625</td>\n",
       "      <td>601c85f7-eafe-4dec-9908-541fea2016ed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Loan originated</td>\n",
       "      <td>7</td>\n",
       "      <td>HUD</td>\n",
       "      <td>Department of Housing and Urban Development</td>\n",
       "      <td>2</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>87</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>66600</td>\n",
       "      <td>104</td>\n",
       "      <td>2320</td>\n",
       "      <td>1485</td>\n",
       "      <td>4.429999828338623</td>\n",
       "      <td>5508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.05000305175781</td>\n",
       "      <td>73761754-e4e8-4170-a1b7-1136bba44d1a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Loan originated</td>\n",
       "      <td>7</td>\n",
       "      <td>HUD</td>\n",
       "      <td>Department of Housing and Urban Development</td>\n",
       "      <td>2</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>86</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>55400</td>\n",
       "      <td>153</td>\n",
       "      <td>948</td>\n",
       "      <td>809</td>\n",
       "      <td>2.490000009536743</td>\n",
       "      <td>2973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.8300018310547</td>\n",
       "      <td>bc299795-2c39-4051-b90a-00a4f7e18695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Loan originated</td>\n",
       "      <td>7</td>\n",
       "      <td>HUD</td>\n",
       "      <td>Department of Housing and Urban Development</td>\n",
       "      <td>2</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>66600</td>\n",
       "      <td>206</td>\n",
       "      <td>2375</td>\n",
       "      <td>2210</td>\n",
       "      <td>5.340000152587891</td>\n",
       "      <td>6044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.06999969482422</td>\n",
       "      <td>581d5ed1-773f-42fa-91f4-502e1554cff8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  action_taken                            action_taken_name agency_code  \\\n",
       "0            1                              Loan originated           7   \n",
       "1            3  Application denied by financial institution           7   \n",
       "2            1                              Loan originated           7   \n",
       "3            1                              Loan originated           7   \n",
       "4            1                              Loan originated           7   \n",
       "\n",
       "  agency_abbr                                  agency_name  \\\n",
       "0         HUD  Department of Housing and Urban Development   \n",
       "1         HUD  Department of Housing and Urban Development   \n",
       "2         HUD  Department of Housing and Urban Development   \n",
       "3         HUD  Department of Housing and Urban Development   \n",
       "4         HUD  Department of Housing and Urban Development   \n",
       "\n",
       "  applicant_ethnicity applicant_ethnicity_name applicant_income_000s  \\\n",
       "0                   2   Not Hispanic or Latino                    75   \n",
       "1                   2   Not Hispanic or Latino                    60   \n",
       "2                   2   Not Hispanic or Latino                    87   \n",
       "3                   2   Not Hispanic or Latino                    86   \n",
       "4                   2   Not Hispanic or Latino                    46   \n",
       "\n",
       "  applicant_race_1 applicant_race_2  ... state_name hud_median_family_income  \\\n",
       "0                5              NaN  ...       Ohio                    66600   \n",
       "1                5              NaN  ...       Ohio                    69100   \n",
       "2                5              NaN  ...       Ohio                    66600   \n",
       "3                5              NaN  ...       Ohio                    55400   \n",
       "4                5              NaN  ...       Ohio                    66600   \n",
       "\n",
       "  loan_amount_000s number_of_1_to_4_family_units  \\\n",
       "0              219                          3165   \n",
       "1              293                          3131   \n",
       "2              104                          2320   \n",
       "3              153                           948   \n",
       "4              206                          2375   \n",
       "\n",
       "  number_of_owner_occupied_units minority_population population rate_spread  \\\n",
       "0                           2746   9.869999885559082      10439         NaN   \n",
       "1                           2921  16.459999084472656       8742         NaN   \n",
       "2                           1485   4.429999828338623       5508         NaN   \n",
       "3                            809   2.490000009536743       2973         NaN   \n",
       "4                           2210   5.340000152587891       6044         NaN   \n",
       "\n",
       "  tract_to_msamd_income                                  uuid  \n",
       "0    148.33999633789062  b73debb0-35a0-4a26-b982-aed4973e497c  \n",
       "1    172.69000244140625  601c85f7-eafe-4dec-9908-541fea2016ed  \n",
       "2     89.05000305175781  73761754-e4e8-4170-a1b7-1136bba44d1a  \n",
       "3     133.8300018310547  bc299795-2c39-4051-b90a-00a4f7e18695  \n",
       "4    126.06999969482422  581d5ed1-773f-42fa-91f4-502e1554cff8  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a quick data snapshot\n",
    "data_lar.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'493,271 total rows  for a total of 38,968,409 data points'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:,.0f}'.format(data_lar.shape[0]) + ' total rows  for a total of ' + \\\n",
    "'{:,.0f}'.format(data_lar.shape[0]*data_lar.shape[1]) + ' data points'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now pull county business patters data from the census bureau\n",
    "census_df = seed.census_pull(init_state, init_yr, data_lar, config.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMP</th>\n",
       "      <th>ESTAB</th>\n",
       "      <th>PAYANN</th>\n",
       "      <th>POP</th>\n",
       "      <th>county_code</th>\n",
       "      <th>county_name</th>\n",
       "      <th>state_abbr</th>\n",
       "      <th>state_code</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3899081</td>\n",
       "      <td>195687</td>\n",
       "      <td>210202807</td>\n",
       "      <td>1250871</td>\n",
       "      <td>35</td>\n",
       "      <td>Cuyahoga County, Ohio</td>\n",
       "      <td>OH</td>\n",
       "      <td>39</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3775265</td>\n",
       "      <td>169990</td>\n",
       "      <td>190400631</td>\n",
       "      <td>1138190</td>\n",
       "      <td>49</td>\n",
       "      <td>Franklin County, Ohio</td>\n",
       "      <td>OH</td>\n",
       "      <td>39</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466581</td>\n",
       "      <td>35316</td>\n",
       "      <td>20664563</td>\n",
       "      <td>227255</td>\n",
       "      <td>85</td>\n",
       "      <td>Lake County, Ohio</td>\n",
       "      <td>OH</td>\n",
       "      <td>39</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201710</td>\n",
       "      <td>14425</td>\n",
       "      <td>7926456</td>\n",
       "      <td>111289</td>\n",
       "      <td>169</td>\n",
       "      <td>Wayne County, Ohio</td>\n",
       "      <td>OH</td>\n",
       "      <td>39</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2809075</td>\n",
       "      <td>125607</td>\n",
       "      <td>159909829</td>\n",
       "      <td>782863</td>\n",
       "      <td>61</td>\n",
       "      <td>Hamilton County, Ohio</td>\n",
       "      <td>OH</td>\n",
       "      <td>39</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EMP   ESTAB     PAYANN      POP  county_code            county_name  \\\n",
       "0  3899081  195687  210202807  1250871           35  Cuyahoga County, Ohio   \n",
       "1  3775265  169990  190400631  1138190           49  Franklin County, Ohio   \n",
       "2   466581   35316   20664563   227255           85      Lake County, Ohio   \n",
       "3   201710   14425    7926456   111289          169     Wayne County, Ohio   \n",
       "4  2809075  125607  159909829   782863           61  Hamilton County, Ohio   \n",
       "\n",
       "  state_abbr  state_code  year  \n",
       "0         OH          39  2016  \n",
       "1         OH          39  2016  \n",
       "2         OH          39  2016  \n",
       "3         OH          39  2016  \n",
       "4         OH          39  2016  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick snapshot\n",
    "census_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'88 total rows  for a total of 792 data points'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:,.0f}'.format(census_df.shape[0]) + ' total rows  for a total of ' + \\\n",
    "'{:,.0f}'.format(census_df.shape[0]*census_df.shape[1]) + ' data points'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, let's pull data about the originating institutions\n",
    "data_inst = seed.inst_pull(init_state, init_yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_year</th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>agency_code</th>\n",
       "      <th>agency_abbr</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>federal_tax_id</th>\n",
       "      <th>respondent_name</th>\n",
       "      <th>respondent_address</th>\n",
       "      <th>respondent_city</th>\n",
       "      <th>respondent_state</th>\n",
       "      <th>...</th>\n",
       "      <th>parent_state</th>\n",
       "      <th>parent_zip_code</th>\n",
       "      <th>respondent_name_panel</th>\n",
       "      <th>respondent_city_panel</th>\n",
       "      <th>respondent_state_panel</th>\n",
       "      <th>other_lender_code</th>\n",
       "      <th>region_code</th>\n",
       "      <th>validity_error</th>\n",
       "      <th>assets</th>\n",
       "      <th>lar_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>0000000046</td>\n",
       "      <td>1</td>\n",
       "      <td>OCC</td>\n",
       "      <td>Office of the Comptroller of the Currency</td>\n",
       "      <td>31-4247738</td>\n",
       "      <td>FIRST NATIONAL BANK OF MCCONNE</td>\n",
       "      <td>86 N. KENNEBEC AVENUE, PO BOX 208</td>\n",
       "      <td>MCCONNELSVILLE</td>\n",
       "      <td>OH</td>\n",
       "      <td>...</td>\n",
       "      <td>OH</td>\n",
       "      <td>43756</td>\n",
       "      <td>FIRST NB</td>\n",
       "      <td>MCCONNELSVILLE</td>\n",
       "      <td>OH</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>138285</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>0000000047</td>\n",
       "      <td>1</td>\n",
       "      <td>OCC</td>\n",
       "      <td>Office of the Comptroller of the Currency</td>\n",
       "      <td>35-0704860</td>\n",
       "      <td>FIRST FINANCIAL BANK NA</td>\n",
       "      <td>1401 S 3RD ST</td>\n",
       "      <td>TERRE HAUTE</td>\n",
       "      <td>IN</td>\n",
       "      <td>...</td>\n",
       "      <td>IN</td>\n",
       "      <td>47807</td>\n",
       "      <td>FIRST FNCL BK NA</td>\n",
       "      <td>TERRE HAUTE</td>\n",
       "      <td>IN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>2882577</td>\n",
       "      <td>2695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>0000000086</td>\n",
       "      <td>1</td>\n",
       "      <td>OCC</td>\n",
       "      <td>Office of the Comptroller of the Currency</td>\n",
       "      <td>31-0294798</td>\n",
       "      <td>FIRST NATIONAL BANK OF GERMANT</td>\n",
       "      <td>17 NORTH MAIN STREET</td>\n",
       "      <td>GERMANTOWN</td>\n",
       "      <td>OH</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FIRST NB</td>\n",
       "      <td>GERMANTOWN</td>\n",
       "      <td>OH</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>52364</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>0000000324</td>\n",
       "      <td>1</td>\n",
       "      <td>OCC</td>\n",
       "      <td>Office of the Comptroller of the Currency</td>\n",
       "      <td>23-0916895</td>\n",
       "      <td>FIRST NATIONAL BANK AND TRUST</td>\n",
       "      <td>40 SOUTH STATE ST</td>\n",
       "      <td>NEWTOWN</td>\n",
       "      <td>PA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FIRST NB&amp;TC NEWTOWN</td>\n",
       "      <td>NEWTOWN</td>\n",
       "      <td>PA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>860869</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>0000000325</td>\n",
       "      <td>1</td>\n",
       "      <td>OCC</td>\n",
       "      <td>Office of the Comptroller of the Currency</td>\n",
       "      <td>24-0558097</td>\n",
       "      <td>FNB BANK, NA</td>\n",
       "      <td>354 MILL STREET</td>\n",
       "      <td>DANVILLE</td>\n",
       "      <td>PA</td>\n",
       "      <td>...</td>\n",
       "      <td>PA</td>\n",
       "      <td>17604</td>\n",
       "      <td>FNB BK NA</td>\n",
       "      <td>DANVILLE</td>\n",
       "      <td>PA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>363285</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  activity_year respondent_id agency_code agency_abbr  \\\n",
       "0          2016    0000000046           1         OCC   \n",
       "1          2016    0000000047           1         OCC   \n",
       "2          2016    0000000086           1         OCC   \n",
       "3          2016    0000000324           1         OCC   \n",
       "4          2016    0000000325           1         OCC   \n",
       "\n",
       "                                 agency_name federal_tax_id  \\\n",
       "0  Office of the Comptroller of the Currency     31-4247738   \n",
       "1  Office of the Comptroller of the Currency     35-0704860   \n",
       "2  Office of the Comptroller of the Currency     31-0294798   \n",
       "3  Office of the Comptroller of the Currency     23-0916895   \n",
       "4  Office of the Comptroller of the Currency     24-0558097   \n",
       "\n",
       "                  respondent_name                 respondent_address  \\\n",
       "0  FIRST NATIONAL BANK OF MCCONNE  86 N. KENNEBEC AVENUE, PO BOX 208   \n",
       "1         FIRST FINANCIAL BANK NA                      1401 S 3RD ST   \n",
       "2  FIRST NATIONAL BANK OF GERMANT               17 NORTH MAIN STREET   \n",
       "3   FIRST NATIONAL BANK AND TRUST                  40 SOUTH STATE ST   \n",
       "4                    FNB BANK, NA                    354 MILL STREET   \n",
       "\n",
       "  respondent_city respondent_state  ... parent_state parent_zip_code  \\\n",
       "0  MCCONNELSVILLE               OH  ...           OH           43756   \n",
       "1     TERRE HAUTE               IN  ...           IN           47807   \n",
       "2      GERMANTOWN               OH  ...          NaN             NaN   \n",
       "3         NEWTOWN               PA  ...          NaN             NaN   \n",
       "4        DANVILLE               PA  ...           PA           17604   \n",
       "\n",
       "  respondent_name_panel respondent_city_panel respondent_state_panel  \\\n",
       "0              FIRST NB        MCCONNELSVILLE                     OH   \n",
       "1      FIRST FNCL BK NA           TERRE HAUTE                     IN   \n",
       "2              FIRST NB            GERMANTOWN                     OH   \n",
       "3   FIRST NB&TC NEWTOWN               NEWTOWN                     PA   \n",
       "4             FNB BK NA              DANVILLE                     PA   \n",
       "\n",
       "  other_lender_code region_code validity_error   assets lar_count  \n",
       "0                 0           3              N   138285       129  \n",
       "1                 0           3              N  2882577      2695  \n",
       "2                 0           3              N    52364        38  \n",
       "3                 0           1              N   860869       184  \n",
       "4                 0           1              N   363285       270  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick snapshot\n",
    "data_inst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100 total rows  for a total of 2,400 data points'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:,.0f}'.format(data_inst.shape[0]) + ' total rows  for a total of ' + \\\n",
    "'{:,.0f}'.format(data_inst.shape[0]*data_inst.shape[1]) + ' data points'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Storage\n",
    "We are very early on, but we have already pulled together a rather large dataset. So, after building on our foundataion of data collection, where we know have functions that can pull and update the necessary data, we need to start thinking about data storage and the tools we are going to need to scale up analysis.\n",
    "\n",
    "For data storage this project will rely on PostgreSQL. This is a powerful, open source object-relational database which is well suited for the type of data we are working with.\n",
    "\n",
    "For processing and analysis we will rely on Spark, which has a deep library for classification and analytics but also is very scalable as more resources can be added to a cluster very easily.\n",
    "\n",
    "Thinking about how we can go to one small slice of data to the entire dataset over all available years ahead of time will save us a lot of headache going forward. To help us in this endeavor I will be using Docker Compose to run these services. This setup will be helpful when we scale up operations as we will see.\n",
    "\n",
    "If you have not already, please follow the instructions in the [README.md](file:///../README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading started\n",
      "Establising connection to database hmda_db listening on 0.0.0.0, port 54320 with user name: postgres.\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "could not connect to server: Cannot assign requested address (0x00002741/10049)\n\tIs the server running on host \"0.0.0.0\" and accepting\n\tTCP/IP connections on port 54320?\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a6e4f0e0a877>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# after the setup we are ready to load the data we have downloaded into our database\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mload\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Projects\\hmda\\py_code\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mdbname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdbname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0muser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     )\n\u001b[0;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\"Connection success.\"\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\psycopg2\\__init__.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[0mdsn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_dsn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnection_factory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconnection_factory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwasync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcursor_factory\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor_factory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcursor_factory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: could not connect to server: Cannot assign requested address (0x00002741/10049)\n\tIs the server running on host \"0.0.0.0\" and accepting\n\tTCP/IP connections on port 54320?\n"
     ]
    }
   ],
   "source": [
    "# after the setup we are ready to load the data we have downloaded into our database\n",
    "import load\n",
    "load.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis, Transformation, & Feature Engineering\n",
    "Now that we have our data loaded, we can begin to do some initial analysis. As we step through the available data we should take care to think about how it can be interpreted and to make sure we set ourselves up for success by looking at abnormal features like outliers or highly skewed distributions.\n",
    "\n",
    "We have done our job in getting the data together and stored. But now we need to make sure we have informative features. In my humble opinion, this is where a lot of value can be added or a things can go wrong so we will spend a fair amount of time in this section. Before we can even truly to any exploratory analysis we will need to preprocess a lot of this data so we can make better sense of it.\n",
    "\n",
    "First and most importantly, if we take a look at the variable we will be trying to predict/classify we can it can take a few different forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(set(data_lar['action_taken_name'])).rename(columns={0:'action_taken_name'})\n",
    "df.style.set_properties(**{'width':'100%', 'text-align':'center'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define what meets our criteria. For this project we are interested in approvals. So if the loan is originated that is an approval, but so is if the application was approved by it was withdrawn by the applicant. On the other hand, we will define application denied by the financial instituion as unapproved but also if the preapproval request was denied by the instituion.\n",
    "\n",
    "This leave several actions that we will filter out of our dataset. These will be:\n",
    "1. When loans are puchased by other institutions\n",
    "2. For incompleteness\n",
    "3. When the applicant withdraws the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lar['action_taken'] = pd.to_numeric(data_lar['action_taken'])\n",
    "lar = data_lar[(data_lar['action_taken'] != 6)]\n",
    "lar = lar[(lar['action_taken'] != 5)]\n",
    "lar = lar[(lar['action_taken'] != 4)]\n",
    "\"\"\"dropped {} observations\"\"\".format(data_lar.shape[0] - lar.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important filter we should impose is when income is missing from the dataset. Income is likely to be one of the most important features here, so if that isn't included in the data we shouldn't include it for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_obs = lar.shape[0]\n",
    "lar = lar[(lar['applicant_income_000s'].apply(lambda x: math.isnan(float(x))) == False)]\n",
    "\"\"\"dropped {} observations\"\"\".format(start_obs - lar.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brief note one dropping observations. Although beyond the scope of this project, it is often worth examining patterns within data where it is missing, where it is an outlier or otherwise strange. In this project we will be removing this data, but in practice just as having data can be informative where data is missing or especially is an outlier can be informative as well.\n",
    "\n",
    "Moving on for now, we need to transform our data from text to our binary classification. 1 for approved and 0 for not approved.\n",
    "\n",
    "It will be important to note how balanced/unbalanced our data is, since a highly unbalanced set will mean an model who selects the more likely outcome will appear to be more correct than it really may be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved = np.zeros(lar.shape[0])\n",
    "ids = (lar['action_taken'] == 1) | (lar['action_taken'] == 2)\n",
    "approved[ids] = 1\n",
    "lar['action_taken'] = approved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lar[['action_taken','action_taken_name']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(lar['action_taken'],facecolor='#3F4B8C',alpha=0.8)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Probability')\n",
    "plt.title('Unbalance Approval/Non-Approval');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While our metric of interest is unbalanced, it is not extremely so.\n",
    "\n",
    "I have already mentioned that I expect income to be an important feature of our data. However, it comes in a few different forms. Let's examine our income data and look at how we might transform them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lar['applicant_income_000s'] = pd.to_numeric(lar['applicant_income_000s'])\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(lar['applicant_income_000s'],100,facecolor='#3F4B8C',alpha=0.8)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Income')\n",
    "plt.title('Applicant Income (in thousands USD)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that this data has a very log-normal looking distribution (i.e. very long right tail). Most models that we will consider have an underlying assumption that the data is normally distributed. It will be important for us to keep the underlying model assumptions in mind through our analysis process.\n",
    "\n",
    "To address this in the income data, we will perform a log transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(lar['applicant_income_000s'].apply(lambda x: math.log(x,10)),100, \\\n",
    "        facecolor='#3F4B8C',alpha=0.8)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Income -- Log 10 Scale')\n",
    "plt.title('Applicant Income (in thousands USD)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you may notice that I choose a base 10 for the log transform. In this case I prefer to work on base 10 for interpretation as it tends to be easier to work in units of 10. Also notice that all of our values are above zero. We could scale this distribution to be above/beow average being above and below zero. This again comes down to distribution. I don't expect above or below average income to be especially important for acceptance, rather it will be proportional to the loan amount. I will always default to less transformation where possible with a keen focus on interpretation.\n",
    "\n",
    "You will also notice now that the ditribution is much more normal looking, but we can also see a very strang blip around zero. Under closer inspection, these are entries of $1 for applicant income. For our purposes, we will filter these outliers from our dataset as they are likely an entry or other type of input error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_obs = lar.shape[0]\n",
    "lar = lar[(lar['applicant_income_000s'] != 1)]\n",
    "\"\"\"dropped {} observations\"\"\".format(start_obs - lar.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The Range of our data is from {} up to {}\"\"\".format(min(lar['applicant_income_000s']), \\\n",
    "                                                      max(lar['applicant_income_000s']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the new range of our data, we can still see an arbitrarily low number of 2 and an equally suspcious high number of 9999. While these are also likely to be entries which are less than accurate, just as in the case of missing data can have information I have kept these in the dataset under they assumption that they can also be informative. For instance, perhaps they represent sentiment of the loan officer. In any case, looking at our new distribution they don't cause the same type of outlier problem we witnessed before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(lar['applicant_income_000s'].apply(lambda x: math.log(x,10)),100, \\\n",
    "        facecolor='#3F4B8C',alpha=0.8)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Income -- Log 10 scale')\n",
    "plt.title('Applicant Income (in thousands USD)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at another example variable, let's look at the number of units in an area that are built to house less than 5 families. This is a good metric, beyond population, for density of an area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lar['number_of_1_to_4_family_units'] = pd.to_numeric(lar['number_of_1_to_4_family_units'])\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(lar['number_of_1_to_4_family_units'], 100, facecolor='#3F4B8C',alpha=0.8)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Living Density')\n",
    "plt.title('Number of Under 5 Family Homes');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again here we have a very strong right tailed distribution. However, in this case moving to a log scale would only shift that right tail to a left tail. Furthermore, looking at the Shapiro-Wilk test of normaily the transformation would move the metric from 0.92 to 0.99. I would not consider that to be a large enough change to be compelling.\n",
    "\n",
    "In this case, I do think scaling the data to be above or below average has more interpretive power. So this is the route I will take when scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(preprocessing.scale(lar['number_of_1_to_4_family_units']), 100, facecolor='#3F4B8C',alpha=0.8)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Living Density -- Normalized')\n",
    "plt.title('Number of Under 5 Family Homes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_data = pd.DataFrame({'loan_amount': pd.to_numeric(lar['loan_amount_000s']), \\\n",
    "                            'income': pd.to_numeric(lar['applicant_income_000s'])})\n",
    "jplot = sns.jointplot(y='loan_amount',x='income', data=income_data, kind='reg', height=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
